{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1654326988973,"user":{"displayName":"Michal Lečbych","userId":"13655313062063653679"},"user_tz":-120},"id":"yy4ZSFyhN-sO","outputId":"c4a6205a-9934-4e77-c2ca-67c33800bf24"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sat Jun  4 07:16:28 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":59344,"status":"error","timestamp":1654327175008,"user":{"displayName":"Michal Lečbych","userId":"13655313062063653679"},"user_tz":-120},"id":"H1MLdGqiuCdU","outputId":"6cc54843-29f9-4449-b4d1-2a7528d9b511"},"outputs":[],"source":["!pip install tensorboardX\n","!pip install --force-reinstall albumentations==1.0.3\n","!pip install opencv-python-headless==4.5.2.52\n","!pip install tensorboardcolab\n","\n","\n","import torch.optim as optim\n","import matplotlib.patches as patches\n","import albumentations as A\n","import cv2\n","import numpy as np\n","import os\n","import pandas as pd\n","import torch.nn.functional as F\n","from PIL import Image, ImageFile\n","from torch.utils.data import Dataset, DataLoader\n","from albumentations.pytorch import ToTensorV2\n","from collections import Counter\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import random\n","import torch\n","import torch.nn as nn\n","import warnings\n","from tensorboardX import SummaryWriter\n","from torchsummary import summary\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZYI8MMXFLis"},"outputs":[],"source":["torch.backends.cudnn.benchmark = True\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","DATASET = '/content/drive/MyDrive'\n","IMG_DIR = DATASET + \"/images1/\"\n","LABEL_DIR = DATASET + \"/labels1/\"\n","CHECKPOINT_FILE = \"checkpoint.pth.tar\"\n","\n","MAP_IOU_THRESH = 0.5\n","NUM_EPOCHS = 200\n","WEIGHT_DECAY = 1e-4\n","NUM_WORKERS = 4\n","NMS_IOU_THRESH = 0.45\n","BATCH_SIZE = 8\n","IMAGE_SIZE = 416\n","NUM_CLASSES = 20\n","LEARNING_RATE = 3e-5\n","CONF_THRESHOLD = 0.05\n","scale = 1.1\n","\n","\n","PIN_MEMORY = True\n","LOAD_MODEL = True\n","SAVE_MODEL = True\n","\n","S = [IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8]\n","ANCHORS = [\n","    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n","    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n","    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n","]\n","\n","PASCAL_CLASSES = [\n","    \"aeroplane\",\n","    \"bicycle\",\n","    \"bird\",\n","    \"boat\",\n","    \"bottle\",\n","    \"bus\",\n","    \"car\",\n","    \"cat\",\n","    \"chair\",\n","    \"cow\",\n","    \"diningtable\",\n","    \"dog\",\n","    \"horse\",\n","    \"motorbike\",\n","    \"person\",\n","    \"pottedplant\",\n","    \"sheep\",\n","    \"sofa\",\n","    \"train\",\n","    \"tvmonitor\"\n","]\n","\n","\"\"\"\n","UTILS\n","\"\"\"\n","train_transforms = A.Compose(\n","    [\n","        A.LongestMaxSize(max_size=int(IMAGE_SIZE * scale)),\n","        A.PadIfNeeded(\n","            min_height=int(IMAGE_SIZE * scale),\n","            min_width=int(IMAGE_SIZE * scale),\n","            border_mode=cv2.BORDER_CONSTANT,\n","        ),\n","        A.RandomCrop(width=IMAGE_SIZE, height=IMAGE_SIZE),\n","        A.ColorJitter(brightness=0.6, contrast=0.6,\n","                      saturation=0.6, hue=0.6, p=0.4),\n","        A.OneOf(\n","            [\n","                A.ShiftScaleRotate(\n","                    rotate_limit=20, p=0.5, border_mode=cv2.BORDER_CONSTANT\n","                ),\n","                A.IAAAffine(shear=15, p=0.5, mode=\"constant\"),\n","            ],\n","            p=1.0,\n","        ),\n","        A.HorizontalFlip(p=0.5),\n","        A.Blur(p=0.1),\n","        A.CLAHE(p=0.1),\n","        A.Posterize(p=0.1),\n","        A.ToGray(p=0.1),\n","        A.ChannelShuffle(p=0.05),\n","        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n","        ToTensorV2(),\n","    ],\n","    bbox_params=A.BboxParams(\n","        format=\"yolo\", min_visibility=0.4, label_fields=[],),\n",")\n","test_transforms = A.Compose(\n","    [\n","        A.LongestMaxSize(max_size=IMAGE_SIZE),\n","        A.PadIfNeeded(\n","            min_height=IMAGE_SIZE, min_width=IMAGE_SIZE, border_mode=cv2.BORDER_CONSTANT\n","        ),\n","        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n","        ToTensorV2(),\n","    ],\n","    bbox_params=A.BboxParams(\n","        format=\"yolo\", min_visibility=0.4, label_fields=[]),\n",")\n","\n","\n","\n","def iou_width_height(boxes1, boxes2):\n","\n","    intersection = torch.min(boxes1[..., 0], boxes2[..., 0]) * torch.min(\n","        boxes1[..., 1], boxes2[..., 1]\n","    )\n","    union = (\n","        boxes1[..., 0] * boxes1[..., 1] +\n","        boxes2[..., 0] * boxes2[..., 1] - intersection\n","    )\n","    return intersection / union\n","\n","\n","def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n","\n","\n","    if box_format == \"midpoint\":\n","        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n","        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n","        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n","        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n","        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n","        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n","        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n","        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n","\n","    x1 = torch.max(box1_x1, box2_x1)\n","    y1 = torch.max(box1_y1, box2_y1)\n","    x2 = torch.min(box1_x2, box2_x2)\n","    y2 = torch.min(box1_y2, box2_y2)\n","\n","    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n","    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n","    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n","\n","    return intersection / (box1_area + box2_area - intersection + 1e-6)\n","\n","\n","def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n","    assert type(bboxes) == list\n","\n","    boxes = [box for box in bboxes if box[1] > threshold]\n","    boxes = sorted(boxes, key=lambda x: x[1], reverse=True)\n","    boxes_after_nms = []\n","\n","    while boxes:\n","        chosen_box = boxes.pop(0)\n","\n","        boxes = [\n","            box\n","            for box in boxes\n","            if box[0] != chosen_box[0]\n","            or intersection_over_union(\n","                torch.tensor(chosen_box[2:]),\n","                torch.tensor(box[2:]),\n","                box_format=box_format,\n","            )\n","            < iou_threshold\n","        ]\n","\n","        boxes_after_nms.append(chosen_box)\n","    return boxes_after_nms\n","\n","\n","def mean_average_precision(\n","    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=20\n","):\n","\n","    average_precisions = []\n","    epsilon = 1e-6\n","\n","    for c in range(num_classes):\n","        detections = []\n","        ground_truths = []\n","\n","        for detection in pred_boxes:\n","            if detection[1] == c:\n","                detections.append(detection)\n","\n","        for true_box in true_boxes:\n","            if true_box[1] == c:\n","                ground_truths.append(true_box)\n","\n","        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n","        for key, val in amount_bboxes.items():\n","            amount_bboxes[key] = torch.zeros(val)\n","\n","        detections.sort(key=lambda x: x[2], reverse=True)\n","        TP = torch.zeros((len(detections)))\n","        FP = torch.zeros((len(detections)))\n","        total_true_bboxes = len(ground_truths)\n","\n","        if total_true_bboxes == 0:\n","            continue\n","\n","        for detection_idx, detection in enumerate(detections):\n","            ground_truth_img = [\n","                bbox for bbox in ground_truths if bbox[0] == detection[0]\n","            ]\n","\n","            num_gts = len(ground_truth_img)\n","            best_iou = 0\n","\n","            for idx, gt in enumerate(ground_truth_img):\n","                iou = intersection_over_union(\n","                    torch.tensor(detection[3:]),\n","                    torch.tensor(gt[3:]),\n","                    box_format=box_format,\n","                )\n","\n","                if iou > best_iou:\n","                    best_iou = iou\n","                    best_gt_idx = idx\n","\n","            if best_iou > iou_threshold:\n","                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n","                    TP[detection_idx] = 1\n","                    amount_bboxes[detection[0]][best_gt_idx] = 1\n","                else:\n","                    FP[detection_idx] = 1\n","            else:\n","                FP[detection_idx] = 1\n","\n","        TP_cumsum = torch.cumsum(TP, dim=0)\n","        FP_cumsum = torch.cumsum(FP, dim=0)\n","        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n","        precisions = TP_cumsum / (TP_cumsum + FP_cumsum + epsilon)\n","        precisions = torch.cat((torch.tensor([1]), precisions))\n","        recalls = torch.cat((torch.tensor([0]), recalls))\n","        average_precisions.append(torch.trapz(precisions, recalls))\n","\n","    return sum(average_precisions) / len(average_precisions)\n","\n","\n","def get_evaluation_bboxes(\n","    loader,\n","    model,\n","    iou_threshold,\n","    anchors,\n","    threshold,\n","    box_format=\"midpoint\",\n","    device=\"cuda\",\n","):\n","    model.eval()\n","    train_idx = 0\n","    all_pred_boxes = []\n","    all_true_boxes = []\n","    for batch_idx, (x, labels) in enumerate(tqdm(loader)):\n","        x = x.to(device)\n","\n","        with torch.no_grad():\n","            predictions = model(x)\n","\n","        batch_size = x.shape[0]\n","        bboxes = [[] for _ in range(batch_size)]\n","        for i in range(3):\n","            S = predictions[i].shape[2]\n","            anchor = torch.tensor([*anchors[i]]).to(device) * S\n","            boxes_scale_i = cells_to_bboxes(\n","                predictions[i], anchor, S=S, is_preds=True\n","            )\n","            for idx, (box) in enumerate(boxes_scale_i):\n","                bboxes[idx] += box\n","\n","        true_bboxes = cells_to_bboxes(\n","            labels[2], anchor, S=S, is_preds=False\n","        )\n","\n","        for idx in range(batch_size):\n","            nms_boxes = non_max_suppression(\n","                bboxes[idx],\n","                iou_threshold=iou_threshold,\n","                threshold=threshold,\n","                box_format=box_format,\n","            )\n","\n","            for nms_box in nms_boxes:\n","                all_pred_boxes.append([train_idx] + nms_box)\n","\n","            for box in true_bboxes[idx]:\n","                if box[1] > threshold:\n","                    all_true_boxes.append([train_idx] + box)\n","\n","            train_idx += 1\n","\n","    model.train()\n","    return all_pred_boxes, all_true_boxes\n","\n","\n","def cells_to_bboxes(predictions, anchors, S, is_preds=True):\n","    BATCH_SIZE = predictions.shape[0]\n","    num_anchors = len(anchors)\n","    box_predictions = predictions[..., 1:5]\n","    if is_preds:\n","        anchors = anchors.reshape(1, len(anchors), 1, 1, 2)\n","        box_predictions[..., 0:2] = torch.sigmoid(box_predictions[..., 0:2])\n","        box_predictions[..., 2:] = torch.exp(\n","            box_predictions[..., 2:]) * anchors\n","        scores = torch.sigmoid(predictions[..., 0:1])\n","        best_class = torch.argmax(predictions[..., 5:], dim=-1).unsqueeze(-1)\n","    else:\n","        scores = predictions[..., 0:1]\n","        best_class = predictions[..., 5:6]\n","\n","    cell_indices = (\n","        torch.arange(S)\n","        .repeat(predictions.shape[0], 3, S, 1)\n","        .unsqueeze(-1)\n","        .to(predictions.device)\n","    )\n","    x = 1 / S * (box_predictions[..., 0:1] + cell_indices)\n","    y = 1 / S * (box_predictions[..., 1:2] +\n","                 cell_indices.permute(0, 1, 3, 2, 4))\n","    w_h = 1 / S * box_predictions[..., 2:4]\n","    converted_bboxes = torch.cat(\n","        (best_class, scores, x, y, w_h), dim=-1).reshape(BATCH_SIZE, num_anchors * S * S, 6)\n","    return converted_bboxes.tolist()\n","\n","\n","def check_class_accuracy(model, loader, threshold):\n","    model.eval()\n","    tot_class_preds, correct_class = 0, 0\n","    tot_noobj, correct_noobj = 0, 0\n","    tot_obj, correct_obj = 0, 0\n","\n","    for idx, (x, y) in enumerate(tqdm(loader)):\n","        x = x.to(DEVICE)\n","        with torch.no_grad():\n","            out = model(x)\n","\n","        for i in range(3):\n","            y[i] = y[i].to(DEVICE)\n","            obj = y[i][..., 0] == 1  \n","            noobj = y[i][..., 0] == 0  \n","\n","            correct_class += torch.sum(\n","                torch.argmax(out[i][..., 5:][obj], dim=-1) == y[i][..., 5][obj]\n","            )\n","            tot_class_preds += torch.sum(obj)\n","\n","            obj_preds = torch.sigmoid(out[i][..., 0]) > threshold\n","            correct_obj += torch.sum(obj_preds[obj] == y[i][..., 0][obj])\n","            tot_obj += torch.sum(obj)\n","            correct_noobj += torch.sum(obj_preds[noobj] == y[i][..., 0][noobj])\n","            tot_noobj += torch.sum(noobj)\n","    print(\n","        f\"Class accuracy is: {(correct_class/(tot_class_preds+1e-16))*100:2f}%\")\n","    print(f\"No obj accuracy is: {(correct_noobj/(tot_noobj+1e-16))*100:2f}%\")\n","    print(f\"Obj accuracy is: {(correct_obj/(tot_obj+1e-16))*100:2f}%\")\n","\n","    model.train()\n","\n","class YOLODataset(Dataset):\n","    def __init__(\n","        self,\n","        csv_file,\n","        img_dir,\n","        label_dir,\n","        anchors,\n","        image_size=416,\n","        S=[13, 26, 52],\n","        C=20,\n","        transform=None,\n","    ):\n","        self.annotations = pd.read_csv(csv_file)\n","        self.img_dir = img_dir\n","        self.label_dir = label_dir\n","        self.image_size = image_size\n","        self.transform = transform\n","        self.S = S\n","        self.anchors = torch.tensor(\n","            anchors[0] + anchors[1] + anchors[2])  # for all 3 scales\n","        self.num_anchors = self.anchors.shape[0]\n","        self.num_anchors_per_scale = self.num_anchors // 3\n","        self.C = C\n","        self.ignore_iou_thresh = 0.5\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        label_path = os.path.join(\n","            self.label_dir, self.annotations.iloc[index, 1])\n","        bboxes = np.roll(np.loadtxt(fname=label_path,\n","                         delimiter=\" \", ndmin=2), 4, axis=1).tolist()\n","        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0])\n","        image = np.array(Image.open(img_path).convert(\"RGB\"))\n","\n","        if self.transform:\n","            augmentations = self.transform(image=image, bboxes=bboxes)\n","            image = augmentations[\"image\"]\n","            bboxes = augmentations[\"bboxes\"]\n","\n","        targets = [torch.zeros((self.num_anchors // 3, S, S, 6))\n","                   for S in self.S]\n","        for box in bboxes:\n","            iou_anchors = iou_width_height(\n","                torch.tensor(box[2:4]), self.anchors)\n","            anchor_indices = iou_anchors.argsort(descending=True, dim=0)\n","            x, y, width, height, class_label = box\n","            has_anchor = [False] * 3 \n","            for anchor_idx in anchor_indices:\n","                scale_idx = anchor_idx // self.num_anchors_per_scale\n","                anchor_on_scale = anchor_idx % self.num_anchors_per_scale\n","                S = self.S[scale_idx]\n","                i, j = int(S * y), int(S * x)\n","                anchor_taken = targets[scale_idx][anchor_on_scale, i, j, 0]\n","                if not anchor_taken and not has_anchor[scale_idx]:\n","                    targets[scale_idx][anchor_on_scale, i, j, 0] = 1\n","                    x_cell, y_cell = S * x - j, S * y - i \n","                    width_cell, height_cell = (\n","                        width * S,\n","                        height * S,\n","                    )  \n","                    box_coordinates = torch.tensor(\n","                        [x_cell, y_cell, width_cell, height_cell]\n","                    )\n","                    targets[scale_idx][anchor_on_scale,\n","                                       i, j, 1:5] = box_coordinates\n","                    targets[scale_idx][anchor_on_scale,\n","                                       i, j, 5] = int(class_label)\n","                    has_anchor[scale_idx] = True\n","\n","                elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\n","                    targets[scale_idx][anchor_on_scale,\n","                                       i, j, 0] = -1  \n","\n","        return image, tuple(targets)\n","\n","\n","\n","\n","def get_loaders(train_csv_path, test_csv_path):\n","\n","    train_dataset = YOLODataset(\n","        train_csv_path,\n","        transform=train_transforms,\n","        S=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8],\n","        img_dir=IMG_DIR,\n","        label_dir=LABEL_DIR,\n","        anchors=ANCHORS,\n","    )\n","    test_dataset = YOLODataset(\n","        test_csv_path,\n","        transform=test_transforms,\n","        S=[IMAGE_SIZE // 32, IMAGE_SIZE // 16, IMAGE_SIZE // 8],\n","        img_dir=IMG_DIR,\n","        label_dir=LABEL_DIR,\n","        anchors=ANCHORS,\n","    )\n","    train_loader = DataLoader(\n","        dataset=train_dataset,\n","        batch_size=BATCH_SIZE,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=PIN_MEMORY,\n","        shuffle=True,\n","        drop_last=False,\n","    )\n","    test_loader = DataLoader(\n","        dataset=test_dataset,\n","        batch_size=BATCH_SIZE,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=PIN_MEMORY,\n","        shuffle=False,\n","        drop_last=False,\n","    )\n","\n","    return train_loader, test_loader\n","\n","\n","\n","class YoloLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.mse = nn.MSELoss()\n","        self.bce = nn.BCEWithLogitsLoss()\n","        self.entropy = nn.CrossEntropyLoss()\n","        self.sigmoid = nn.Sigmoid()\n","\n","        self.lambda_class = 1\n","        self.lambda_noobj = 10\n","        self.lambda_obj = 1\n","        self.lambda_box = 10\n","\n","    def forward(self, predictions, target, anchors, writer, length, epoch, i):\n","        obj = target[..., 0] == 1 \n","        noobj = target[..., 0] == 0 \n","\n","        no_object_loss = self.bce(\n","            (predictions[..., 0:1][noobj]), (target[..., 0:1][noobj]),\n","        )\n","\n","        anchors = anchors.reshape(1, 3, 1, 1, 2)\n","        box_preds = torch.cat([self.sigmoid(predictions[..., 1:3]), torch.exp(\n","            predictions[..., 3:5]) * anchors], dim=-1)\n","        ious = intersection_over_union(\n","            box_preds[obj], target[..., 1:5][obj]).detach()\n","        object_loss = self.mse(self.sigmoid(\n","            predictions[..., 0:1][obj]), ious * target[..., 0:1][obj])\n","\n","        predictions[..., 1:3] = self.sigmoid(\n","            predictions[..., 1:3])\n","        target[..., 3:5] = torch.log(\n","            (1e-16 + target[..., 3:5] / anchors)\n","        ) \n","        box_loss = self.mse(predictions[..., 1:5][obj], target[..., 1:5][obj])\n","\n","        class_loss = self.entropy(\n","            (predictions[..., 5:][obj]), (target[..., 5][obj].long()),\n","        )\n","       \n","        \n","        if i % 2000 == 0:\n","          \n","            writer.add_scalar(\n","                            \"Regression_loss\",\n","                            self.lambda_box * box_loss,\n","                            epoch,\n","                            \n","                        )\n","            writer.add_scalar(\n","                            \"Confidence_loss\",\n","                            self.lambda_obj * object_loss + self.lambda_noobj * no_object_loss,\n","                            epoch,\n","                        )\n","            writer.add_scalar(\n","                            \"Classification_loss\",\n","                            self.lambda_class * class_loss,\n","                            epoch,\n","                        )\n","            writer.add_scalar(\n","                            \"Total_loss\",\n","                            self.lambda_box * box_loss\n","                            + self.lambda_obj * object_loss\n","                            + self.lambda_noobj * no_object_loss\n","                            + self.lambda_class * class_loss,\n","                            epoch,\n","                        )\n","\n","\n","        return (\n","            self.lambda_box * box_loss\n","            + self.lambda_obj * object_loss\n","            + self.lambda_noobj * no_object_loss\n","            + self.lambda_class * class_loss\n","        )\n","\n","\n","class Conv(nn.Module):\n","    def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\n","        super().__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels,\n","                              bias=not bn_act, **kwargs)\n","        self.bn = nn.BatchNorm2d(out_channels)\n","        self.leaky = Mish()\n","        self.use_bn_act = bn_act\n","\n","    def forward(self, x):\n","        if self.use_bn_act:\n","            return self.leaky(self.bn(self.conv(x)))\n","        else:\n","            return self.conv(x)\n","\n","\n","class Mish(nn.Module):\n","    def __init__(self):\n","        super(Mish, self).__init__()\n","\n","    def forward(self, x):\n","        return x * torch.tanh(F.softplus(x))\n","\n","\n","class ConvBlock(nn.Module):\n","\n","    def __init__(self, dim, drop_path=0.0, layer_scale_init_value=1e-6):\n","        super().__init__()\n","        self.dwconv = nn.Conv2d(\n","            dim, dim, kernel_size=7, padding=3, groups=dim\n","        )  # depthwise conv\n","        self.norm = nn.BatchNorm2d(dim)\n","        self.pwconv1 = nn.Linear(\n","            dim, 4 * dim\n","        )  # pointwise/1x1 convs, implemented with linear layers\n","        self.act = Mish()\n","        self.pwconv2 = nn.Linear(4 * dim, dim)\n","        self.gamma = (\n","            nn.Parameter(layer_scale_init_value *\n","                         torch.ones((dim)), requires_grad=True)\n","            if layer_scale_init_value > 0\n","            else None\n","        )\n","        self.drop_path = nn.Identity()\n","\n","    def forward(self, x):\n","        input = x\n","        x = self.dwconv(x)\n","        x = self.norm(x)\n","        x = x.permute(0, 2, 3, 1)  # (N, C, H, W) -> (N, H, W, C)\n","        x = self.pwconv1(x)\n","        x = self.act(x)\n","        x = self.pwconv2(x)\n","        if self.gamma is not None:\n","            x = self.gamma * x\n","        x = x.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n","\n","        x = input + self.drop_path(x)\n","        return x\n","\n","\n","class Scale(nn.Module):\n","    def __init__(self, in_channels, num_classes):\n","        super().__init__()\n","        self.pred = nn.Sequential(\n","            Conv(in_channels, 2 * in_channels, kernel_size=3, padding=1),\n","            Conv(\n","                2 * in_channels, (num_classes + 5) * 3, bn_act=False, kernel_size=1\n","            ),\n","        )\n","        self.num_classes = num_classes\n","\n","    def forward(self, x):\n","        return (\n","            self.pred(x)\n","            .reshape(x.shape[0], 3, self.num_classes + 5, x.shape[2], x.shape[3])\n","            .permute(0, 1, 3, 4, 2)\n","        )\n","\n","\n","class SpatialPyramidPooling(nn.Module):\n","    def __init__(self, feature_channels, pool_sizes=[5, 9, 13]):\n","        super(SpatialPyramidPooling, self).__init__()\n","\n","        self.head_conv = nn.Sequential(\n","            Conv(feature_channels[-1],\n","                 feature_channels[-1] // 2, kernel_size=1),\n","        )\n","\n","        self.maxpools = nn.ModuleList(\n","            [\n","                nn.MaxPool2d(pool_size, 1, pool_size // 2)\n","                for pool_size in pool_sizes\n","            ]\n","        )\n","        self.__initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.head_conv(x)\n","        features = [maxpool(x) for maxpool in self.maxpools]\n","        features = torch.cat([x] + features, dim=1)\n","\n","        return features\n","\n","    def __initialize_weights(self):\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                m.weight.data.normal_(0, 0.01)\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","\n","class ResBlock(nn.Module):\n","    def __init__(self, channels, use_residual=True, num_repeats=1):\n","        super().__init__()\n","        self.layers = nn.ModuleList()\n","        for repeat in range(num_repeats):\n","            self.layers += [\n","                nn.Sequential(\n","                    ConvBlock(channels)\n","                )\n","            ]\n","\n","        self.use_residual = use_residual\n","        self.num_repeats = num_repeats\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","\n","class MyModel(nn.Module):\n","    def __init__(self, in_channels=3, num_classes=20):\n","        super().__init__()\n","        self.num_classes = num_classes\n","        self.in_channels = in_channels\n","        self.depths = [64, 128, 256, 512, 1024]\n","        self.num_repeats = [1, 2, 5, 5, 4]\n","        self.up = [512, 256, 128]\n","        self.feature_channels = [256, 512, 1024]\n","\n","        start = nn.Sequential(\n","            Conv(in_channels, 32, kernel_size=3, stride=1, padding=1),\n","            Conv(32, 64, kernel_size=3, stride=2, padding=1),\n","        )\n","\n","        self.downsample_layers = nn.ModuleList()\n","        self.downsample_layers.append(start)\n","        for i in range(4):\n","            downsample = nn.Sequential(\n","                Conv(self.depths[i], self.depths[i+1],\n","                     kernel_size=3, stride=2, padding=1),\n","            )\n","            self.downsample_layers.append(downsample)\n","\n","        self.stages = nn.ModuleList()\n","        for i in range(5):\n","            stage = nn.Sequential(\n","                ResBlock(channels=self.depths[i], use_residual=True,\n","                         num_repeats=self.num_repeats[i])\n","            )\n","\n","            self.stages.append(stage)\n","\n","        scale1 = Scale(512, num_classes=self.num_classes)\n","        scale2 = Scale(256, num_classes=self.num_classes)\n","        scale3 = Scale(128, num_classes=self.num_classes)\n","        self.scales = nn.ModuleList()\n","        self.scales.append(scale1)\n","        self.scales.append(scale2)\n","        self.scales.append(scale3)\n","\n","        route1 = nn.Sequential(\n","            Conv(1024, 1024, kernel_size=3, stride=1, padding=1),\n","            ResBlock(1024, use_residual=False),\n","            Conv(1024, 512, kernel_size=1),\n","        )\n","\n","        route2 = nn.Sequential(\n","            Conv(768, 256, kernel_size=1, stride=1, padding=0),\n","            Conv(256, 512, kernel_size=3, stride=1, padding=1),\n","            ResBlock(512, use_residual=False),\n","            Conv(512, 256, kernel_size=1),\n","        )\n","\n","        route3 = nn.Sequential(\n","            Conv(384, 128, kernel_size=1, stride=1, padding=0),\n","            Conv(128, 256, kernel_size=3, stride=1, padding=1),\n","            ResBlock(256, use_residual=False),\n","            Conv(256, 128, kernel_size=1),\n","        )\n","        self.routes = nn.ModuleList()\n","        self.routes.append(route1)\n","        self.routes.append(route2)\n","        self.routes.append(route3)\n","\n","        self.upsample = nn.ModuleList()\n","        for i in range(2):\n","            upsample = nn.Sequential(\n","                Conv(self.up[i], self.up[i+1],\n","                     kernel_size=1, stride=1, padding=0),\n","                nn.Upsample(scale_factor=2)\n","            )\n","            self.upsample.append(upsample)\n","\n","        self.spp = SpatialPyramidPooling(self.feature_channels)\n","        self.downstream_conv = nn.Sequential(\n","            Conv(2048, 1024, kernel_size=3, stride=1, padding=1),\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"¨¨¨¨¨¨¨¨¨¨BACKBONE¨¨¨¨¨¨¨¨¨¨¨\"\"\"\n","        routes = []\n","        for i in range(5):\n","            x = self.downsample_layers[i](x)\n","            x = self.stages[i](x)\n","            if self.num_repeats[i] == 5:\n","                routes.append(x)\n","        \"\"\"¨¨¨¨¨¨¨¨¨¨BACKBONE¨¨¨¨¨¨¨¨¨¨¨\"\"\"\n","\n","        \"\"\"-----------NECK---------------\"\"\"\n","        x = self.spp(x)\n","        x = self.downstream_conv(x)\n","        \"\"\"-----------NECK--------------\"\"\"\n","\n","        \"\"\"-----------HEAD-------------\"\"\"\n","\n","        outs = []\n","        for i in range(2):\n","            x = self.routes[i](x)\n","            outs.append(self.scales[i](x))\n","            x = self.upsample[i](x)\n","            x = torch.cat([x, routes[-i-1]], dim=1)\n","\n","        x = self.routes[-1](x)\n","        outs.append(self.scales[-1](x))\n","        \"\"\"-----------HEAD-------------\"\"\"\n","\n","        return outs\n","\n","\n","\n","\n","\n","\n","def train_fn(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors, writer, epoch):\n","    loop = tqdm(train_loader, leave=True)\n","    losses = []\n","    length = len(train_loader)\n","    for batch_idx, (x, y) in enumerate(loop):\n","        x = x.to(DEVICE)\n","        y0, y1, y2 = (\n","            y[0].to(DEVICE),\n","            y[1].to(DEVICE),\n","            y[2].to(DEVICE),\n","        )\n","\n","        with torch.cuda.amp.autocast():\n","            out = model(x)\n","            loss = (\n","                loss_fn(out[0], y0, scaled_anchors[0], writer, length, epoch, batch_idx)\n","                + loss_fn(out[1], y1, scaled_anchors[1], writer, length, epoch, batch_idx)\n","                + loss_fn(out[2], y2, scaled_anchors[2], writer, length, epoch, batch_idx)\n","            )\n","            \n","        losses.append(loss.item())\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        mean_loss = sum(losses) / len(losses)\n","        loop.set_postfix(loss=mean_loss)\n","\n","\n","class Trainer(object):\n","  def __init__(self, weight_path, train_loader, test_loader):\n","      self.start_epoch = 0\n","      self.best_mAP = 0.0\n","      self.weight_path = weight_path\n","      self.train_loader = train_loader\n","      self.test_loader = test_loader\n","      self.model = MyModel().to(DEVICE)\n","      self.optimizer = optim.AdamW(self.model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","      self.loss_fn = YoloLoss()\n","      self.scaler = torch.cuda.amp.GradScaler()\n","      self.scaled_anchors = (\n","        torch.tensor(ANCHORS)\n","        * torch.tensor(S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n","    ).to(DEVICE)\n","      self.save = '/content/drive/MyDrive/YOLOv3_version2.pth.tar'\n","\n","\n","  def load_checkpoint(self,checkpoint_file, lr):\n","    print(\"=> Loading checkpoint\")\n","    print(checkpoint_file)\n","    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n","    self.model.load_state_dict(checkpoint[\"state_dict\"])\n","    self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","    self.start_epoch = checkpoint[\"epoch\"] + 1\n","\n","    for param_group in self.optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","  def save_checkpoint(self, filename, epoch, mAP):\n","    print(\"=> Saving checkpoint\")\n","    checkpoint = {\n","        \"state_dict\": self.model.state_dict(),\n","        \"optimizer\": self.optimizer.state_dict(),\n","        \"epoch\": epoch,\n","        \"best_mAP\": mAP,\n","    }\n","    torch.save(checkpoint, filename)\n","\n","  def train(self, writer):\n","    mAP = 0\n","\n","    if LOAD_MODEL:\n","        self.load_checkpoint(\n","            self.weight_path, LEARNING_RATE\n","        )\n","\n","\n","    for epoch in range(self.start_epoch, NUM_EPOCHS):\n","        print(epoch)\n","        loop = tqdm(self.train_loader, leave=True)\n","        losses = []\n","        length = len(self.train_loader)\n","        for batch_idx, (x, y) in enumerate(loop):\n","            x = x.to(DEVICE)\n","            y0, y1, y2 = (\n","                y[0].to(DEVICE),\n","                y[1].to(DEVICE),\n","                y[2].to(DEVICE),\n","            )\n","\n","            with torch.cuda.amp.autocast():\n","                out = self.model(x)\n","                loss = (\n","                    self.loss_fn(out[0], y0, self.scaled_anchors[0], writer, length, epoch, batch_idx)\n","                    + self.loss_fn(out[1], y1, self.scaled_anchors[1], writer, length, epoch, batch_idx)\n","                    + self.loss_fn(out[2], y2, self.scaled_anchors[2], writer, length, epoch, batch_idx)\n","                )\n","\n","            losses.append(loss.item())\n","            self.optimizer.zero_grad()\n","            self.scaler.scale(loss).backward()\n","            self.scaler.step(self.optimizer)\n","            self.scaler.update()\n","\n","            mean_loss = sum(losses) / len(losses)\n","            loop.set_postfix(loss=mean_loss)\n","\n","        if SAVE_MODEL:\n","            self.save_checkpoint(filename=self.save, epoch=epoch, mAP=mAP)\n","            \n","        if epoch % 5 == 0:\n","            check_class_accuracy(self.model, self.test_loader,\n","                                 threshold=CONF_THRESHOLD)\n","            pred_boxes, true_boxes = get_evaluation_bboxes(\n","                self.test_loader,\n","                self.model,\n","                iou_threshold=NMS_IOU_THRESH,\n","                anchors=ANCHORS,\n","                threshold=CONF_THRESHOLD,\n","            )\n","            mapval = mean_average_precision(\n","                pred_boxes,\n","                true_boxes,\n","                iou_threshold=MAP_IOU_THRESH,\n","                box_format=\"midpoint\",\n","                num_classes=NUM_CLASSES,\n","            )\n","            print(f\"MAP: {mapval.item()}\")\n","            self.model.train()\n","            writer.add_scalar(\n","                            \"MAP\",\n","                            mapval.item(),\n","                            epoch,\n","                        )\n","          \n","def main():\n","    log_path = 'YOLO/COLAB_train/tensorboard'\n","    writer = SummaryWriter(logdir=log_path + \"/MyModel\")\n","    train_loader, test_loader = get_loaders(\n","        train_csv_path=\"/content/drive/MyDrive/train.csv\", test_csv_path=\"/content/drive/MyDrive/test.csv\"\n","    )\n","    weight_path = '/content/drive/MyDrive/YOLOv3_version1.pth.tar'\n","\n","\n","    Trainer(weight_path, train_loader, test_loader).train(writer)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3aIb_JtZFSII"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5008,"status":"ok","timestamp":1654173813829,"user":{"displayName":"Michal Lečbych","userId":"13655313062063653679"},"user_tz":-120},"id":"2h_is5SBFTcp","outputId":"8861585e-aaaf-4a53-8c3e-452c5780458f"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":838},"executionInfo":{"elapsed":608,"status":"ok","timestamp":1654173905660,"user":{"displayName":"Michal Lečbych","userId":"13655313062063653679"},"user_tz":-120},"id":"ophNnWaoFpBT","outputId":"54d21184-7751-489d-f206-a8ece2992aed"},"outputs":[],"source":["%load_ext tensorboard%\n","tensorboard --logdir=/content/drive/MyDrive/puvodni_znova"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iCvCyWqUIwND","outputId":"8c1d504f-5ad7-4528-c54c-92a2dbdd8f09"},"outputs":[],"source":["main()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPKz5v7TKJWxjJxNXfEXVRb","collapsed_sections":[],"mount_file_id":"15T1G30cVloGsrynyDgPEmiJhL8TD2apU","name":"MyModel.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.4"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
